{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb19e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews for positive class: 2001122, Number of reviews for negative class: 445349, Number of reviews for neutral class: 193686\n",
      "\n",
      "\n",
      "Average length before cleaning: 318.93 characters\n",
      "Average length after cleaning: 305.24 characters\n",
      "\n",
      "Average length before preprocessing: 318.93 characters\n",
      "Average length after preprocessing: 194.82 characters\n",
      "\n",
      "\n",
      "Train:  (160000, 126317) (160000,) Test:  (40000, 126317) (40000,)\n",
      "\n",
      "\n",
      "Perceptron Training Set Metrics:\n",
      "\n",
      "\n",
      "Accuracy for Perceptron Training set: 92.62%\n",
      "Precision for Perceptron Training set: 0.93\n",
      "Recall for Perceptron Training set: 0.93\n",
      "F1-Score for Perceptron Training set: 0.93\n",
      "\n",
      "Perceptron Testing Set Metrics:\n",
      "\n",
      "\n",
      "Accuracy for Perceptron Testing set: 86.98%\n",
      "Precision for Perceptron Testing set: 0.87\n",
      "Recall for Perceptron Testing set: 0.87\n",
      "F1-Score for Perceptron Testing set: 0.87\n",
      "\n",
      "LinearSVC (Training) Set Metrics:\n",
      "\n",
      "\n",
      "Accuracy for LinearSVC (Training) set: 94.94%\n",
      "Precision for LinearSVC (Training) set: 0.95\n",
      "Recall for LinearSVC (Training) set: 0.95\n",
      "F1-Score for LinearSVC (Training) set: 0.95\n",
      "\n",
      "LinearSVC (Testing) Set Metrics:\n",
      "\n",
      "\n",
      "Accuracy for LinearSVC (Testing) set: 90.88%\n",
      "Precision for LinearSVC (Testing) set: 0.91\n",
      "Recall for LinearSVC (Testing) set: 0.91\n",
      "F1-Score for LinearSVC (Testing) set: 0.91\n",
      "\n",
      "Logistic Regression (Training) Set Metrics:\n",
      "\n",
      "\n",
      "Accuracy for Logistic Regression (Training) set: 92.28%\n",
      "Precision for Logistic Regression (Training) set: 0.92\n",
      "Recall for Logistic Regression (Training) set: 0.92\n",
      "F1-Score for Logistic Regression (Training) set: 0.92\n",
      "\n",
      "Logistic Regression (Testing) Set Metrics:\n",
      "\n",
      "\n",
      "Accuracy for Logistic Regression (Testing) set: 91.18%\n",
      "Precision for Logistic Regression (Testing) set: 0.91\n",
      "Recall for Logistic Regression (Testing) set: 0.91\n",
      "F1-Score for Logistic Regression (Testing) set: 0.91\n",
      "\n",
      "Multinomial Naive Bayes (Training) Set Metrics:\n",
      "\n",
      "\n",
      "Accuracy for Multinomial Naive Bayes (Training) set: 88.40%\n",
      "Precision for Multinomial Naive Bayes (Training) set: 0.89\n",
      "Recall for Multinomial Naive Bayes (Training) set: 0.88\n",
      "F1-Score for Multinomial Naive Bayes (Training) set: 0.88\n",
      "\n",
      "Multinomial Naive Bayes (Testing) Set Metrics:\n",
      "\n",
      "\n",
      "Accuracy for Multinomial Naive Bayes (Testing) set: 86.66%\n",
      "Precision for Multinomial Naive Bayes (Testing) set: 0.87\n",
      "Recall for Multinomial Naive Bayes (Testing) set: 0.87\n",
      "F1-Score for Multinomial Naive Bayes (Testing) set: 0.87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t', on_bad_lines='skip')\n",
    "    df = df[['review_body', 'star_rating']].dropna().reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def sentiment_class(rating):\n",
    "    rating = float(rating)\n",
    "    if rating > 3:\n",
    "        return 1\n",
    "    elif rating <= 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def display_sentiment_statistics(df, total_ratings):\n",
    "    review_count = df['sentiment'].value_counts().sort_index()\n",
    "\n",
    "    positive_reviews, negative_reviews, neutral_reviews = review_count[1], review_count[0], review_count[2]\n",
    "\n",
    "    total_reviews = sum(review_count)\n",
    "\n",
    "    print(f\"Number of reviews for positive class: {positive_reviews}, Number of reviews for negative class: {negative_reviews}, Number of reviews for neutral class: {neutral_reviews}\")\n",
    "    \n",
    "\n",
    "def filter_reviews(df):\n",
    "    positive_reviews = df[df['sentiment'] == 1].sample(100000, random_state=30)\n",
    "    negative_reviews = df[df['sentiment'] == 0].sample(100000, random_state=30)\n",
    "\n",
    "    df_new = pd.concat([positive_reviews, negative_reviews])\n",
    "    df_new = df_new[df_new['sentiment'] != 2]\n",
    "\n",
    "    return df_new  \n",
    "\n",
    "def expand_contractions(s):\n",
    "    contraction_patterns = {\n",
    "        r\"won't\": \"will not\",\n",
    "        r\"would't\": \"would not\",\n",
    "        r\"could'nt\": \"could not\",\n",
    "        r\"can't\": \"can not\",\n",
    "        r\"n't\": \" not\",\n",
    "        r\"\\'re\": \" are\",\n",
    "        r\"\\'s\": \" is\",\n",
    "        r\"\\'ll\": \" will\",\n",
    "        r\"\\'t\": \" not\",\n",
    "        r\"\\'ve\": \" have\",\n",
    "        r\"I've\": \"I have\",\n",
    "        r\"I'm\": \"I am\"\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in contraction_patterns.items():\n",
    "        s = re.sub(pattern, replacement, s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def clean_reviews(df):\n",
    "    df['review_body'] = df['review_body'].astype(str)\n",
    "    df['cleaned_reviews'] = (\n",
    "        df['review_body']\n",
    "        .str.lower()\n",
    "        .apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "        .apply(lambda x: re.sub(r'https?://\\S+', '', x))\n",
    "        .apply(expand_contractions)\n",
    "        .apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "        .apply(lambda x: x.strip())\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_average_lengths(df):\n",
    "    avg_length_before_cleaning = df['review_body'].apply(len).mean()\n",
    "    avg_length_after_cleaning = df['cleaned_reviews'].apply(len).mean()\n",
    "\n",
    "    print(f\"Average length before cleaning: {avg_length_before_cleaning:.2f} characters\")\n",
    "    print(f\"Average length after cleaning: {avg_length_after_cleaning:.2f} characters\")\n",
    "\n",
    "def preprocess_reviews(df):\n",
    "    custom_stopwords_list = set(stopwords.words('english')) - {'not', 'no', 'nor', 'neither', 'but', 'however', 'although'}\n",
    "    df['cleaned_reviews'] = df['cleaned_reviews'].apply(lambda x: \" \".join([word for word in x.split() if word not in custom_stopwords_list]))\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['cleaned_reviews'] = df['cleaned_reviews'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))\n",
    "\n",
    "    avg_length_before_cleaning = df['review_body'].apply(len).mean()\n",
    "    avg_length_after_cleaning = df['cleaned_reviews'].apply(len).mean()\n",
    "\n",
    "    print(f\"\\nAverage length before preprocessing: {avg_length_before_cleaning:.2f} characters\")\n",
    "    print(f\"Average length after preprocessing: {avg_length_after_cleaning:.2f} characters\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def vectorize_and_split(df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['cleaned_reviews'])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(tfidf_matrix, df['sentiment'], test_size=0.2, random_state=30)\n",
    "\n",
    "    print(\"Train: \", X_train.shape, Y_train.shape, \"Test: \", X_test.shape, Y_test.shape)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def print_metrics(prefix, true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    print(f\"{prefix} Set Metrics:\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy for {} set: {:.2f}%\".format(prefix, accuracy * 100))\n",
    "    print(\"Precision for {} set: {:.2f}\".format(prefix, precision))\n",
    "    print(\"Recall for {} set: {:.2f}\".format(prefix, recall))\n",
    "    print(\"F1-Score for {} set: {:.2f}\".format(prefix, f1))\n",
    "    print()\n",
    "    \n",
    "def train_perceptron_model(X_train, Y_train, X_test, Y_test):\n",
    "    perceptron_model = Perceptron()\n",
    "    perceptron_model.fit(X_train, Y_train)\n",
    "\n",
    "    train_predictions = perceptron_model.predict(X_train)\n",
    "    test_predictions = perceptron_model.predict(X_test)\n",
    "\n",
    "    print_metrics(\"Perceptron Training\", Y_train, train_predictions)\n",
    "    print_metrics(\"Perceptron Testing\", Y_test, test_predictions)\n",
    "\n",
    "    return perceptron_model\n",
    "\n",
    "def train_svm_model(X_train, Y_train, X_test, Y_test):\n",
    "    linear_svc_model = LinearSVC()\n",
    "    linear_svc_model.fit(X_train, Y_train)\n",
    "\n",
    "    linear_svc_train_predictions = linear_svc_model.predict(X_train)\n",
    "    linear_svc_test_predictions = linear_svc_model.predict(X_test)\n",
    "\n",
    "    print_metrics(\"LinearSVC (Training)\", Y_train, linear_svc_train_predictions)\n",
    "    print_metrics(\"LinearSVC (Testing)\", Y_test, linear_svc_test_predictions)\n",
    "\n",
    "    return linear_svc_model\n",
    "\n",
    "def train_logistic_regression_model(X_train, Y_train, X_test, Y_test):\n",
    "    logistic_regression_model = LogisticRegression()\n",
    "\n",
    "    logistic_regression_model.fit(X_train, Y_train)\n",
    "\n",
    "    logistic_regression_train_predictions = logistic_regression_model.predict(X_train)\n",
    "    logistic_regression_test_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "    print_metrics(\"Logistic Regression (Training)\", Y_train, logistic_regression_train_predictions)\n",
    "    print_metrics(\"Logistic Regression (Testing)\", Y_test, logistic_regression_test_predictions)\n",
    "\n",
    "    return logistic_regression_model\n",
    "\n",
    "def train_naive_bayes_model(X_train, Y_train, X_test, Y_test):\n",
    "    naive_bayes_model = MultinomialNB()\n",
    "    naive_bayes_model.fit(X_train, Y_train)\n",
    "\n",
    "    naive_bayes_train_predictions = naive_bayes_model.predict(X_train)\n",
    "    naive_bayes_test_predictions = naive_bayes_model.predict(X_test)\n",
    "\n",
    "    print_metrics(\"Multinomial Naive Bayes (Training)\", Y_train, naive_bayes_train_predictions)\n",
    "    print_metrics(\"Multinomial Naive Bayes (Testing)\", Y_test, naive_bayes_test_predictions)\n",
    "\n",
    "    return naive_bayes_model\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    file_path = \"amazon_reviews_us_Office_Products_v1_00.tsv\"\n",
    "    \n",
    "    df = load_dataset(file_path)\n",
    "    \n",
    "    df['sentiment'] = df['star_rating'].apply(sentiment_class)\n",
    "    \n",
    "    total_ratings = len(df)\n",
    "    \n",
    "    display_sentiment_statistics(df, total_ratings)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    df = filter_reviews(df)\n",
    "    \n",
    "    cleaned_df = clean_reviews(df)\n",
    "    \n",
    "    calculate_average_lengths(df)\n",
    "    \n",
    "    df = preprocess_reviews(df)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = vectorize_and_split(df)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    trained_perceptron_model = train_perceptron_model(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    trained_svm_model = train_svm_model(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    trained_logistic_regression_model = train_logistic_regression_model(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    trained_naive_bayes_model = train_naive_bayes_model(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205fee25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
